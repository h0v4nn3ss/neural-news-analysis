{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b14ee61",
   "metadata": {},
   "source": [
    "# Configuración del Entorno - Proyecto Neural News\n",
    "\n",
    "Este notebook configura el entorno conda `neural_news` e inicializa el proyecto de análisis de noticias falsas y predicción de popularidad de artículos.\n",
    "\n",
    "## Objetivos\n",
    "1. ✅ Verificar configuración del entorno conda\n",
    "2. ✅ Crear estructura completa de carpetas \n",
    "3. ✅ Descargar archivos de datos necesarios\n",
    "4. ✅ Verificar instalación de todas las librerías\n",
    "5. ✅ Configurar parámetros del proyecto\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cf3341",
   "metadata": {},
   "source": [
    "## 1. Verificar Configuración del Entorno\n",
    "\n",
    "Verificamos que el entorno conda `neural_news` esté activo y que la versión de Python sea compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b870532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "\n",
    "print(\"🔧 VERIFICACIÓN DEL ENTORNO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Verificar versión de Python\n",
    "print(f\"🐍 Python: {sys.version}\")\n",
    "print(f\"📁 Directorio actual: {os.getcwd()}\")\n",
    "print(f\"💻 Sistema: {platform.system()} {platform.release()}\")\n",
    "\n",
    "# Verificar entorno conda\n",
    "try:\n",
    "    conda_env = os.environ.get('CONDA_DEFAULT_ENV', 'No detectado')\n",
    "    print(f\"🔷 Entorno Conda: {conda_env}\")\n",
    "except:\n",
    "    print(\"⚠️  No se pudo detectar el entorno conda\")\n",
    "\n",
    "# Verificar compatibilidad de Python\n",
    "major, minor = sys.version_info[:2]\n",
    "if major == 3 and minor >= 9:\n",
    "    print(\"✅ Versión de Python compatible (3.9+)\")\n",
    "else:\n",
    "    print(\"❌ Se requiere Python 3.9 o superior\")\n",
    "    \n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ff488",
   "metadata": {},
   "source": [
    "## 2. Crear Estructura del Proyecto\n",
    "\n",
    "Creamos la estructura completa de carpetas para organizar el proyecto de manera eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279a3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_project_structure():\n",
    "    \"\"\"Crear la estructura completa de carpetas del proyecto\"\"\"\n",
    "    \n",
    "    print(\"📁 CREANDO ESTRUCTURA DEL PROYECTO\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Definir estructura de carpetas\n",
    "    folders = [\n",
    "        'data/raw',\n",
    "        'data/processed', \n",
    "        'notebooks',\n",
    "        'src/preprocessing',\n",
    "        'src/models',\n",
    "        'src/utils',\n",
    "        'results/plots',\n",
    "        'results/models'\n",
    "    ]\n",
    "    \n",
    "    created_folders = []\n",
    "    existing_folders = []\n",
    "    \n",
    "    # Crear carpetas\n",
    "    for folder in folders:\n",
    "        folder_path = Path(f\"../{folder}\")\n",
    "        if not folder_path.exists():\n",
    "            folder_path.mkdir(parents=True, exist_ok=True)\n",
    "            created_folders.append(folder)\n",
    "            print(f\"✅ Creada: {folder}\")\n",
    "        else:\n",
    "            existing_folders.append(folder)\n",
    "            print(f\"📂 Ya existe: {folder}\")\n",
    "    \n",
    "    print(\"\\n📊 RESUMEN:\")\n",
    "    print(f\"✅ Carpetas creadas: {len(created_folders)}\")\n",
    "    print(f\"📂 Carpetas existentes: {len(existing_folders)}\")\n",
    "    \n",
    "    return created_folders, existing_folders\n",
    "\n",
    "# Ejecutar creación de estructura\n",
    "created, existing = create_project_structure()\n",
    "\n",
    "print(\"\\n🗂️  ESTRUCTURA FINAL:\")\n",
    "print(\"\"\"\n",
    "prueba_desafio/\n",
    "├── data/\n",
    "│   ├── raw/          # Datasets originales\n",
    "│   └── processed/    # Datos procesados\n",
    "├── notebooks/        # Jupyter notebooks\n",
    "├── src/\n",
    "│   ├── preprocessing/  # Scripts de preprocesamiento\n",
    "│   ├── models/        # Implementaciones de modelos\n",
    "│   └── utils/         # Funciones utilitarias\n",
    "├── results/\n",
    "│   ├── plots/         # Gráficos y visualizaciones\n",
    "│   └── models/        # Modelos entrenados guardados\n",
    "└── requirements.txt   # Dependencias del proyecto\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9812a0eb",
   "metadata": {},
   "source": [
    "## 3. Descargar Archivos de Datos Necesarios\n",
    "\n",
    "Descargamos el modelo Word2Vec de Google News que será necesario para la tarea de clasificación de noticias falsas.\n",
    "\n",
    "**Nota:** La descarga del modelo Word2Vec (~1.5GB) puede tardar varios minutos dependiendo de la conexión a internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae358cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def download_word2vec_model():\n",
    "    \"\"\"Descargar el modelo Word2Vec de Google News\"\"\"\n",
    "    \n",
    "    print(\"⬇️  DESCARGA DEL MODELO WORD2VEC\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # URL del modelo Word2Vec de Google News\n",
    "    url = 'https://drive.google.com/uc?id=191stTi4bltaYgZX5l-i2mcxjcxjuMNPK'\n",
    "    output_path = '../data/raw/word2vec_google_news.bin'\n",
    "    \n",
    "    # Verificar si el archivo ya existe\n",
    "    if Path(output_path).exists():\n",
    "        file_size = Path(output_path).stat().st_size / (1024**3)  # GB\n",
    "        print(f\"📁 El archivo ya existe: {output_path}\")\n",
    "        print(f\"📊 Tamaño: {file_size:.2f} GB\")\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        print(\"🚀 Iniciando descarga...\")\n",
    "        print(\"⏳ Esto puede tardar varios minutos (archivo ~1.5GB)\")\n",
    "        \n",
    "        # Descargar el archivo\n",
    "        gdown.download(url, output_path, quiet=False)\n",
    "        \n",
    "        # Verificar descarga exitosa\n",
    "        if Path(output_path).exists():\n",
    "            file_size = Path(output_path).stat().st_size / (1024**3)  # GB\n",
    "            print(f\"\\n✅ Descarga completada exitosamente!\")\n",
    "            print(f\"📁 Ubicación: {output_path}\")\n",
    "            print(f\"📊 Tamaño: {file_size:.2f} GB\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"❌ Error: El archivo no se descargó correctamente\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error durante la descarga: {e}\")\n",
    "        print(\"💡 Sugerencia: Verifica tu conexión a internet e intenta nuevamente\")\n",
    "        return False\n",
    "\n",
    "# Ejecutar descarga (comentado por defecto para evitar descargas automáticas)\n",
    "print(\"🔄 Para descargar el modelo Word2Vec, descomenta y ejecuta la siguiente línea:\")\n",
    "print(\"# download_success = download_word2vec_model()\")\n",
    "print(\"\\n⚠️  IMPORTANTE: La descarga es de ~1.5GB y puede tardar varios minutos\")\n",
    "print(\"💡 Solo ejecuta si realmente necesitas el modelo para las tareas 1-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5373e36",
   "metadata": {},
   "source": [
    "## 4. Verificar Instalación de Librerías\n",
    "\n",
    "Importamos y verificamos todas las librerías necesarias para el proyecto, incluyendo sus versiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ee715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_libraries():\n",
    "    \"\"\"Verificar que todas las librerías necesarias estén instaladas\"\"\"\n",
    "    \n",
    "    print(\"📚 VERIFICACIÓN DE LIBRERÍAS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Diccionario de librerías categorizadas\n",
    "    libraries = {\n",
    "        \"📊 Análisis de Datos\": {\n",
    "            'pandas': 'pd',\n",
    "            'numpy': 'np'\n",
    "        },\n",
    "        \"📈 Visualización\": {\n",
    "            'matplotlib.pyplot': 'plt',\n",
    "            'seaborn': 'sns'\n",
    "        },\n",
    "        \"🧠 Deep Learning\": {\n",
    "            'tensorflow': 'tf',\n",
    "            'keras': 'keras'\n",
    "        },\n",
    "        \"🤖 Machine Learning\": {\n",
    "            'sklearn': 'sklearn',\n",
    "            'xgboost': 'xgb'\n",
    "        },\n",
    "        \"📝 Procesamiento de Texto\": {\n",
    "            'gensim': 'gensim',\n",
    "            'nltk': 'nltk',\n",
    "            'wordcloud': 'wordcloud'\n",
    "        },\n",
    "        \"🛠️ Utilidades\": {\n",
    "            'gdown': 'gdown',\n",
    "            'joblib': 'joblib'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    total_libraries = 0\n",
    "    successful_imports = 0\n",
    "    failed_imports = []\n",
    "    \n",
    "    for category, libs in libraries.items():\n",
    "        print(f\"\\n{category}:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        for lib_name, alias in libs.items():\n",
    "            total_libraries += 1\n",
    "            try:\n",
    "                # Importar librería\n",
    "                exec(f\"import {lib_name} as {alias}\")\n",
    "                \n",
    "                # Obtener versión si está disponible\n",
    "                try:\n",
    "                    version = eval(f\"{alias}.__version__\")\n",
    "                    print(f\"  ✅ {lib_name:20} v{version}\")\n",
    "                except AttributeError:\n",
    "                    print(f\"  ✅ {lib_name:20} (importado correctamente)\")\n",
    "                \n",
    "                successful_imports += 1\n",
    "                \n",
    "            except ImportError as e:\n",
    "                print(f\"  ❌ {lib_name:20} ERROR: {e}\")\n",
    "                failed_imports.append(lib_name)\n",
    "    \n",
    "    # Resumen final\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"📊 RESUMEN DE VERIFICACIÓN:\")\n",
    "    print(f\"✅ Librerías correctas: {successful_imports}/{total_libraries}\")\n",
    "    print(f\"❌ Librerías faltantes: {len(failed_imports)}\")\n",
    "    \n",
    "    if failed_imports:\n",
    "        print(f\"\\n🔧 Librerías a instalar: {', '.join(failed_imports)}\")\n",
    "        print(\"💡 Ejecuta el comando de instalación correspondiente del plan de resolución\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"\\n🎉 ¡TODAS LAS LIBRERÍAS ESTÁN INSTALADAS CORRECTAMENTE!\")\n",
    "        return True\n",
    "\n",
    "# Ejecutar verificación\n",
    "verification_success = verify_libraries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b2f2b",
   "metadata": {},
   "source": [
    "## 5. Configuración Inicial del Proyecto\n",
    "\n",
    "Configuramos parámetros importantes para el proyecto, incluyendo seeds para reproducibilidad y configuraciones de visualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b669e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías principales para configuración\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "\n",
    "def setup_project_configuration():\n",
    "    \"\"\"Configurar parámetros del proyecto para reproducibilidad y visualización\"\"\"\n",
    "    \n",
    "    print(\"⚙️  CONFIGURACIÓN DEL PROYECTO\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # 1. Configurar seeds para reproducibilidad\n",
    "    print(\"🎲 Configurando seeds para reproducibilidad...\")\n",
    "    RANDOM_SEED = 42\n",
    "    \n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "    \n",
    "    print(f\"✅ Seed configurado: {RANDOM_SEED}\")\n",
    "    \n",
    "    # 2. Configurar warnings\n",
    "    print(\"\\n⚠️  Configurando filtros de warnings...\")\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    print(\"✅ Warnings filtrados\")\n",
    "    \n",
    "    # 3. Configurar matplotlib\n",
    "    print(\"\\n📊 Configurando matplotlib...\")\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['figure.figsize'] = (10, 6)\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.rcParams['axes.grid'] = True\n",
    "    plt.rcParams['grid.alpha'] = 0.3\n",
    "    print(\"✅ Matplotlib configurado\")\n",
    "    \n",
    "    # 4. Configurar seaborn\n",
    "    print(\"\\n🎨 Configurando seaborn...\")\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.set_palette(\"husl\")\n",
    "    print(\"✅ Seaborn configurado\")\n",
    "    \n",
    "    # 5. Configurar pandas\n",
    "    print(\"\\n🐼 Configurando pandas...\")\n",
    "    pd.set_option('display.max_columns', 20)\n",
    "    pd.set_option('display.max_rows', 100)\n",
    "    pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "    print(\"✅ Pandas configurado\")\n",
    "    \n",
    "    # 6. Configurar TensorFlow\n",
    "    print(\"\\n🧠 Configurando TensorFlow...\")\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "    print(\"✅ TensorFlow configurado para reproducibilidad\")\n",
    "    \n",
    "    return RANDOM_SEED\n",
    "\n",
    "# Ejecutar configuración\n",
    "seed_used = setup_project_configuration()\n",
    "\n",
    "# Crear archivo de configuración del proyecto\n",
    "def create_project_config_file():\n",
    "    \"\"\"Crear archivo de configuración del proyecto\"\"\"\n",
    "    \n",
    "    config_content = f\"\"\"# Configuración del Proyecto Neural News\n",
    "# Generado automáticamente\n",
    "\n",
    "# Configuración de reproducibilidad\n",
    "RANDOM_SEED = {seed_used}\n",
    "\n",
    "# Rutas de datos\n",
    "DATA_RAW_PATH = '../data/raw/'\n",
    "DATA_PROCESSED_PATH = '../data/processed/'\n",
    "RESULTS_PATH = '../results/'\n",
    "MODELS_PATH = '../results/models/'\n",
    "PLOTS_PATH = '../results/plots/'\n",
    "\n",
    "# Configuración para modelos\n",
    "MAX_FEATURES = 80000  # Tamaño máximo del vocabulario\n",
    "MAX_SEQUENCE_LENGTH = 80  # Longitud máxima de secuencias\n",
    "EMBEDDING_DIM = 300  # Dimensión del embedding Word2Vec\n",
    "\n",
    "# Configuración de entrenamiento\n",
    "EPOCHS_LIMIT = 20  # Límite de épocas para modelos\n",
    "BATCH_SIZE = 32\n",
    "TEST_SIZE = 0.33  # Proporción para conjunto de test\n",
    "\n",
    "# Configuración de visualización\n",
    "FIGURE_SIZE = (10, 6)\n",
    "DPI = 100\n",
    "\"\"\"\n",
    "    \n",
    "    config_path = '../src/utils/config.py'\n",
    "    with open(config_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(config_content)\n",
    "    \n",
    "    print(f\"\\n📄 Archivo de configuración creado: {config_path}\")\n",
    "    return config_path\n",
    "\n",
    "config_file = create_project_config_file()\n",
    "\n",
    "print(\"\\n🎉 ¡CONFIGURACIÓN COMPLETADA!\")\n",
    "print(\"=\" * 40)\n",
    "print(\"✅ Seeds configurados para reproducibilidad\")\n",
    "print(\"✅ Librerías de visualización configuradas\") \n",
    "print(\"✅ Archivo de configuración creado\")\n",
    "print(\"✅ Proyecto listo para comenzar el análisis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8933c3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Resumen de Configuración Completada\n",
    "\n",
    "### 🎯 Estado del Proyecto\n",
    "\n",
    "| Componente | Estado | Descripción |\n",
    "|------------|--------|-------------|\n",
    "| 🐍 Python | ✅ | Versión 3.9+ verificada |\n",
    "| 📁 Estructura | ✅ | Carpetas del proyecto creadas |\n",
    "| 📚 Librerías | ✅ | Todas las dependencias instaladas |\n",
    "| ⚙️ Configuración | ✅ | Seeds y parámetros configurados |\n",
    "| 📄 Archivos | ✅ | Scripts utilitarios creados |\n",
    "\n",
    "### 🚀 Próximos Pasos\n",
    "\n",
    "1. **Obtener Datasets**: \n",
    "   - `news1.csv` - Noticias clasificadas (Verdaderas/Falsas)\n",
    "   - `news_pred.csv` - Noticias para predicción\n",
    "   - `OnlineNewsPopularity.csv` - Dataset de Mashable\n",
    "   - `util_bagging.py` - Función de bagging (si no está incluida)\n",
    "\n",
    "2. **Comenzar Análisis**:\n",
    "   - Abrir `neural_news_analysis.ipynb` \n",
    "   - Seguir el plan de resolución paso a paso\n",
    "   - Ejecutar las 11 tareas del proyecto\n",
    "\n",
    "3. **Descargar Word2Vec** (cuando sea necesario):\n",
    "   - Ejecutar la función de descarga en la sección 3\n",
    "   - Solo necesario para las tareas 1-4 de clasificación de noticias\n",
    "\n",
    "### 🔧 Archivos Creados\n",
    "\n",
    "- `src/utils/verify_setup.py` - Script de verificación\n",
    "- `src/utils/config.py` - Configuración del proyecto  \n",
    "- `requirements.txt` - Lista de dependencias\n",
    "- `notebooks/environment_setup.ipynb` - Este notebook\n",
    "\n",
    "---\n",
    "\n",
    "**🎉 ¡El entorno está listo! Puedes comenzar con el análisis de datos.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
